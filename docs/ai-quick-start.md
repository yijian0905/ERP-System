# ğŸš€ AI æœå‹™å¿«é€Ÿé–‹å§‹æŒ‡å—

## ä¸€éµè¨­ç½®ï¼ˆDockerï¼‰

```bash
# å•Ÿå‹•æ‰€æœ‰ AI æœå‹™ï¼ˆL2 + L3ï¼‰
docker-compose --profile ai up -d

# ä¸‹è¼‰ Ollama æ¨¡å‹
docker exec -it erp-ollama ollama pull llama2

# é©—è­‰æœå‹™
# Windows:
.\scripts\test-ai-services.ps1
# Linux/Mac:
./scripts/test-ai-services.sh
```

## æœ¬åœ°é–‹ç™¼è¨­ç½®

### L2 æœå‹™ï¼ˆPython AIï¼‰

```bash
cd apps/ai-service
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
cp env.example.txt .env
uvicorn app.main:app --reload --port 8000
```

### L3 æœå‹™ï¼ˆOllamaï¼‰

```bash
# ä¸‹è¼‰ä¸¦å®‰è£: https://ollama.ai/download
ollama pull llama2
# Ollama æœƒè‡ªå‹•åœ¨ http://localhost:11434 é‹è¡Œ
```

## é©—è­‰

| æœå‹™ | URL | æª¢æŸ¥å‘½ä»¤ |
|------|-----|----------|
| Python AI | http://localhost:8000 | `curl http://localhost:8000/health` |
| Ollama | http://localhost:11434 | `curl http://localhost:11434/api/tags` |

## ç’°å¢ƒè®Šæ•¸

åœ¨ `apps/api/.env` ä¸­è¨­ç½®ï¼š

```env
AI_SERVICE_URL=http://localhost:8000
OLLAMA_API_URL=http://localhost:11434
```

## è©³ç´°æ–‡æª”

- [å®Œæ•´è¨­ç½®æŒ‡å—](ai-setup-guide.md)
- [API æ–‡æª”](../README.md#api-documentation)


